{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-12T01:47:18.005912Z",
     "start_time": "2025-06-12T01:47:16.618206Z"
    }
   },
   "source": [
    "# ------------------------------------------------------------------\n",
    "# 0. Imports & paths\n",
    "# ------------------------------------------------------------------\n",
    "import json, pathlib\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RAW_FILE  = pathlib.Path(\"../data/processed/master_data.jsonl\")   # or .json\n",
    "SPLIT_DIR = pathlib.Path(\"../data/splits\")\n",
    "SPLIT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1. Load JSONL *or* JSON array\n",
    "# ------------------------------------------------------------------\n",
    "def load_raw(path: pathlib.Path) -> pd.DataFrame:\n",
    "    if path.suffix == \".jsonl\":\n",
    "        with path.open() as f:\n",
    "            rows = [json.loads(l) for l in f if l.strip()]\n",
    "    elif path.suffix == \".json\":\n",
    "        rows = json.loads(path.read_text())\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported extension: {path.suffix}\")\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "df = load_raw(RAW_FILE)\n",
    "print(\"Loaded\", len(df), \"rows -> columns:\", list(df.columns))\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2. Column constants (from your schema)\n",
    "# ------------------------------------------------------------------\n",
    "VULN_COL  = \"vulnerable_code\"\n",
    "FIXED_COL = \"fixed_code\"\n",
    "LABEL_COL = \"is_vuln\"\n",
    "CODE_COL  = \"Function before\"        # name used by Task-5 notebook\n",
    "CVSS_COL = \"cvss\"\n",
    "# CVSS_COL = \"cvss_v3\"          # <-- adjust to real column name\n",
    "\n",
    "assert {VULN_COL, FIXED_COL}.issubset(df.columns), \\\n",
    "    \"Expected columns 'vulnerable_code' and 'fixed_code' not found!\"\n",
    "\n",
    "# simple mapping by CWE (expand as needed)\n",
    "cwe2cvss = {\n",
    "    \"CWE-119\": 7.5,   # buffer overflow → high\n",
    "    \"CWE-20\":  6.0,   # input validation → medium\n",
    "}\n",
    "df[\"cvss\"] = df[\"cwe_id\"].map(cwe2cvss).fillna(5.0)  # default 5.0\n",
    "# ------------------------------------------------------------------\n",
    "# 3. Build labelled table\n",
    "# ------------------------------------------------------------------\n",
    "vuln_df = (\n",
    "    df[[VULN_COL]]\n",
    "    .rename(columns={VULN_COL: CODE_COL})\n",
    "    .assign(**{LABEL_COL: 1})\n",
    ")\n",
    "\n",
    "clean_df = (\n",
    "    df[[FIXED_COL]]\n",
    "    .rename(columns={FIXED_COL: CODE_COL})\n",
    "    .assign(**{LABEL_COL: 0})\n",
    ")\n",
    "\n",
    "combo_df = (\n",
    "    pd.concat([vuln_df, clean_df], ignore_index=True)\n",
    "      .dropna(subset=[CODE_COL])          # weed out blanks\n",
    ")\n",
    "combo_df[\"cvss\"] = df[CVSS_COL] if CVSS_COL in df.columns else 5.0\n",
    "print(\"Labelled table:\", combo_df.shape)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4. Stratified 80 / 10 / 10 split\n",
    "# ------------------------------------------------------------------\n",
    "train_df, temp_df = train_test_split(\n",
    "    combo_df,\n",
    "    test_size=0.20,\n",
    "    stratify=combo_df[LABEL_COL],\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "valid_df, test_df = train_test_split(\n",
    "    temp_df,\n",
    "    test_size=0.50,\n",
    "    stratify=temp_df[LABEL_COL],\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "print(f\"train:{len(train_df)}  valid:{len(valid_df)}  test:{len(test_df)}\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 5. Write out JSONL files\n",
    "# ------------------------------------------------------------------\n",
    "def to_jsonl(frame: pd.DataFrame, outfile: pathlib.Path) -> None:\n",
    "    with outfile.open(\"w\", encoding=\"utf-8\") as w:\n",
    "        for _, row in frame.iterrows():\n",
    "            w.write(json.dumps({\n",
    "                CODE_COL: row[CODE_COL],\n",
    "                LABEL_COL: int(row[LABEL_COL]),\n",
    "                \"cvss\": float(row[\"cvss\"])\n",
    "            }, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "to_jsonl(train_df, SPLIT_DIR / \"train.jsonl\")\n",
    "to_jsonl(valid_df, SPLIT_DIR / \"valid.jsonl\")\n",
    "to_jsonl(test_df,  SPLIT_DIR / \"test.jsonl\")\n",
    "\n",
    "print(\"✅  JSONL splits written to\", SPLIT_DIR)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 352 rows -> columns: ['cwe_id', 'cwe_description', 'vulnerable_code', 'fixed_code', 'analysis', ',cwe_description']\n",
      "Labelled table: (704, 3)\n",
      "train:563  valid:70  test:71\n",
      "✅  JSONL splits written to ..\\data\\splits\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
